# https://github.com/apache/airflow/blob/main/chart/values.yaml

useStandardNaming: true

createUserJob:
  useHelmHooks: false
  applyCustomEnv: false
  jobAnnotations:
    "argocd.argoproj.io/hook": Sync
migrateDatabaseJob:
  useHelmHooks: false
  applyCustomEnv: false
  jobAnnotations:
    "argocd.argoproj.io/hook": Sync

#{{- $numWorkers := 1 }}
#{{- $workerConcurrency := 5 }}
#{{- $maxMemoryPerWorker := 1 }}
#{{- $maxMemoryPerTask := (divf (mulf 0.8 $maxMemoryPerWorker) $workerConcurrency) | printf "%.1f" }}

config:
  celery:
    worker_concurrency: "{{ $workerConcurrency }}"
    extra_celery_config: '{"worker_max_memory_per_child": {{ $maxMemoryPerTask }}}'

extraEnv: |
  - name: "AIRFLOW__API__BASE_URL"
    value: "https://data-airflow.{{ .StateValues.gateway_hostname }}"

  - name: "CLIENT_ID"
    value: "airflow"
  - name: "CLIENT_SECRET"
    value: "{{ .StateValues.security_github_client_secret }}"
  - name: "OIDC_ISSUER"
    value: "https://security-dex.{{ .StateValues.gateway_hostname }}/dex"

  - name: "TRINO_HOST"
    value: "{{ $.Values.release_name }}-data-trino-trino:8080"
  - name: "TRINO_PORT"
    value: "8080"
  - name: "TRINO_USER"
    value: "{{ $.StateValues.default_admin_user}}"
  - name: "S3_AWS_ENDPOINT"
    value: "https://{{ .Values.s3_endpoint }}"
  - name: "S3_AWS_ACCESS_KEY"
    valueFrom:
      secretKeyRef:
        name: s3-credentials
        key: accessKey
  - name: "S3_AWS_SECRET_KEY"
    valueFrom:
      secretKeyRef:
        name: s3-credentials
        key: secretKey

nodeSelector:
  kubernetes.io/arch: arm64

postgresql:
  enabled: false
redis:
  enabled: false

apiSecretKey: "{{ .StateValues.security_github_client_secret | trunc 32 }}"
jwtSecret: "{{ .StateValues.security_github_client_secret | trunc 32 }}"

data:
  metadataSecretName: postgresql-admin-credentials
  brokerUrlSecretName: valkey-admin-credentials

apiServer:
  apiServerConfig: |
    {{- readFile "../files/scripts/airflow/webserver_config.py" | nindent 4 }}
  env:
    - name: "AIRFLOW__API__WORKERS"
      value: "1"
  resources:
    limits:
      cpu: 1
      memory: 1Gi
    requests:
      cpu: 1
      memory: 1Gi

workers:
  replicas: {{$numWorkers}}

  resources:
    limits:
      cpu: 750m
      memory: "{{ $maxMemoryPerWorker }}Gi"
    requests:
      cpu: 750m
      memory: "{{ $maxMemoryPerWorker }}Gi"

  persistence:
    enabled: true
    size: 2Gi
    storageClassName: longhorn-no-replica

  logGroomerSidecar: &logGroomerSidecar
    enabled: true

    frequencyMinutes: 120
    resources:
      limits:
        cpu: 200m
        memory: 256Mi
      requests:
        cpu: 200m
        memory: 256Mi

  livenessProbe: &livenessProbe
    timeoutSeconds: 40

dags:
  gitSync:
    enabled: true

    repo: ssh://git@github.com/datahub-local/datahub-local-workflows.git

    ref: main
    branch: main
    rev: HEAD

    subPath: "workflows/airflow/dags"

    sshKeySecret: github-airflow-auth
    period: 60s

dagProcessor:
  resources:
    limits:
      cpu: 750m
      memory: 768Mi
    requests:
      cpu: 750m
      memory: 768Mi

  livenessProbe: *livenessProbe

statsd:
  resources:
    limits:
      cpu: 250m
      memory: 256Mi
    requests:
      cpu: 250m
      memory: 256Mi

scheduler:
  resources:
    limits:
      cpu: 750m
      memory: 768Mi
    requests:
      cpu: 750m
      memory: 768Mi

  logGroomerSidecar: *logGroomerSidecar

  livenessProbe: *livenessProbe

triggerer:
  resources:
    limits:
      cpu: 750m
      memory: 768Mi
    requests:
      cpu: 750m
      memory: 768Mi

  persistence:
    enabled: true
    size: 0.5Gi
    storageClassName: longhorn-no-replica

  logGroomerSidecar: *logGroomerSidecar

  livenessProbe: *livenessProbe
