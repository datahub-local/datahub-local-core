ollama:
  gpu:
    enabled: true
    type: "nvidia"
    number: 1
  models:
    pull:
      - gemma3:4b-it-qat
      - phi4-mini:3.8b
      - qwen2.5-coder:1.5b-base
      - nomic-embed-text

updateStrategy:
  type: Recreate

runtimeClassName: nvidia

persistentVolume:
  enabled: true
  storageClass: local-path

tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule

ingress:
  enabled: true

  className: "nginx"
  annotations:
    #{{- if .Values.security_enabled }}{{ .Values.security_oauth2_annotations | toYaml | nindent 4 }}{{ end }}

    gethomepage.dev/enabled: "true"
    gethomepage.dev/name: "Ollama"
    gethomepage.dev/pod-selector: "app.kubernetes.io/name=ollama"
    gethomepage.dev/description: "Get up and running with Llama 3, Mistral, Gemma 2, and other large language models."
    gethomepage.dev/group: "Data"
    gethomepage.dev/icon: "sh-ollama"

  # The list of hostnames to be covered with this ingress record.
  hosts:
    - host: "data-ollama.{{ .StateValues.ingress_hostname }}"
      paths:
        - path: /
          pathType: Prefix
