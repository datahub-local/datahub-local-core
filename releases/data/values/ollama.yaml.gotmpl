ollama:
  gpu:
    enabled: true
    type: "nvidia"
    number: 1
  models:
    - llama3-8B
    - deepseek-coder-v2:16b
    - starcoder2:3b

updateStrategy:
  type: Recreate

runtimeClassName: nvidia

persistentVolume:
  enabled: true
  storageClass: local-path

tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule

ingress:
  enabled: true

  className: "traefik"
  annotations:
    traefik.ingress.kubernetes.io/router.entrypoints: websecure
    traefik.ingress.kubernetes.io/router.middlewares: "{{ if .Values.security_enabled }}security-security-oauth2@kubernetescrd{{ end }}"

    gethomepage.dev/enabled: "true"
    gethomepage.dev/name: "Ollama"
    gethomepage.dev/pod-selector: "app.kubernetes.io/name=ollama"
    gethomepage.dev/description: "Get up and running with Llama 3, Mistral, Gemma 2, and other large language models."
    gethomepage.dev/group: "Data"
    gethomepage.dev/icon: "ollama.png"

  # The list of hostnames to be covered with this ingress record.
  hosts:
    - host: "data-ollama.{{ .StateValues.ingress_hostname }}"
      paths:
        - path: /
          pathType: Prefix
