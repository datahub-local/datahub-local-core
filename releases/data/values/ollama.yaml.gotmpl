ollama:
  gpu:
    enabled: true
    type: "nvidia"
    number: 0.5
  models:
    - llama3

runtimeClassName: nvidia

persistentVolume:
  enabled: true

  storageClass: local-path

tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule
