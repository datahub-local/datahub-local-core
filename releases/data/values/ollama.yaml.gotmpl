ollama:
  gpu:
    enabled: true
    type: "nvidia"
    number: 1
  models:
    - phi3.5
    - llama3.1:8b
    - deepseek-coder-v2:16b
    - starcoder2:3b

updateStrategy:
  type: Recreate

runtimeClassName: nvidia

persistentVolume:
  enabled: true
  storageClass: local-path

tolerations:
  - key: nvidia.com/gpu
    operator: Exists
    effect: NoSchedule

ingress:
  enabled: true

  className: "nginx"
  annotations:
    #{{- if .Values.security_enabled }}{{ .Values.security_oauth2_annotations | toYaml | nindent 4 }}{{ end }}

    gethomepage.dev/enabled: "true"
    gethomepage.dev/name: "Ollama"
    gethomepage.dev/pod-selector: "app.kubernetes.io/name=ollama"
    gethomepage.dev/description: "Get up and running with Llama 3, Mistral, Gemma 2, and other large language models."
    gethomepage.dev/group: "Data"
    gethomepage.dev/icon: "ollama.svg"

  # The list of hostnames to be covered with this ingress record.
  hosts:
    - host: "data-ollama.{{ .StateValues.ingress_hostname }}"
      paths:
        - path: /
          pathType: Prefix
