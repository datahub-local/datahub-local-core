# https://github.com/8gears/n8n-helm-chart/blob/main/charts/n8n/values.yaml

_shared_config:
  hostname: &hostname automation-n8n.{{ .StateValues.ingress_hostname }}
  url: &url https://automation-n8n.{{ .StateValues.ingress_hostname }}

  env: &sharedEnv
    DB_POSTGRESDB_USER:
      valueFrom:
        secretKeyRef:
          name: postgresql-admin-credentials
          key: user
    DB_POSTGRESDB_PASSWORD:
      valueFrom:
        secretKeyRef:
          name: postgresql-admin-credentials
          key: password

    N8N_LICENSE_ACTIVATION_KEY:
      valueFrom:
        secretKeyRef:
          name: n8n-secrets
          key: N8N_LICENSE_ACTIVATION_KEY

    N8N_EXTERNAL_STORAGE_S3_ACCESS_KEY:
      valueFrom:
        secretKeyRef:
          name: backup-kopia-auth
          key: AWS_ACCESS_KEY_ID
    N8N_EXTERNAL_STORAGE_S3_ACCESS_SECRET:
      valueFrom:
        secretKeyRef:
          name: backup-kopia-auth
          key: AWS_SECRET_ACCESS_KEY

    QUEUE_BULL_REDIS_PASSWORD:
      valueFrom:
        secretKeyRef:
          name: valkey-admin-credentials
          key: password

    BACKUP_GITHUB_REPO_OWNER:
      value: "datahub-local"
    BACKUP_GITHUB_REPO_NAME:
      value: "datahub-local-workflows"
    BACKUP_GITHUB_REPO_PATH:
      value: "n8n"

image:
  repository: n8nio/n8n
  tag: '{{ range $key,$value := .StateValues.container_image_version }}{{ if (eq $key "n8nio/n8n") }}{{ $value }}{{ end }}{{ end }}'

main:
  config:
    generic_timezone: UTC

    webhook_url: *url
    vue_app_url_base_api: *url

    executions_mode: queue
    offload_manual_executions_to_workers: true
    n8n:
      log_level: debug
      metrics: true
      metrics_include_api_endpoints: true
      metrics_include_queue_metrics: true
      metrics_include_workflow_id_label: true

      runners_enabled: true

      hide_usage_page: true
      hiring_banner_enabled: false
      diagnostics_enabled: false
      version_notifications_enabled: false
      enforce_settings_file_permissions: false

      custom_extensions: /home/node/node_modules

    queue:
      health:
        check:
          active: true
      bull:
        redis:
          host: "{{ .Values.release_name }}-data-valkey-headless.data.svc.cluster.local"
          port: 6379

    db:
      type: postgresdb
      postgresdb:
        host: "{{ $.Values.release_name }}-data-postgresql-hl.data.svc.cluster.local"
        port: 5432
        pool:
          size: 10

    external:
      storage:
        s3:
          host: "{{ .Values.release_name }}-data-minio.data.svc.cluster.local:9000"
          protocol: http
          bucket_name: datahub-local-n8n

    node:
      function_allow_external: "*"

    custom:
      credentials_file: /n8n-secrets/credentials.json
      # extra_modules: "@extractus/article-extractor"
      community_nodes: "n8n-nodes-puppeteer,n8n-nodes-webpage-content-extractor"
  secret:
    n8n:
      encryption_key: "{{ .StateValues.security_github_client_secret }}"

    custom:
      # Set easy credentials because it is authenticated by reverse proxy.
      instance_owner_email: admin@example.com
      instance_owner_password: Password01
      oauth2_proxy_middleware_enabled: true

      flaresolverr_url: http://datahub-local-core-media-servarr-flaresolverr.media.svc.cluster.local:8191

  extraEnv:
    <<: *sharedEnv

    #{{- if .Values.security_enabled }}
    EXTERNAL_HOOK_FILES:
      value: /n8n-config-scripts/n8n-ready-hook.js
    N8N_READY:
      value: n8n-ready-hook.js
    #{{ end }}

  command: &command
    - sh
    - /n8n-config-scripts/n8n-start.sh
  podSecurityContext: &podSecurityContext
    runAsNonRoot: false
    runAsUser: 0
    runAsGroup: 0
    fsGroup: 0

  readinessProbe: &readinessProbe
    httpGet:
      path: /healthz/readiness

    initialDelaySeconds: 120
    timeoutSeconds: 30
  livenessProbe: &livenessProbe
    initialDelaySeconds: 120
    periodSeconds: 120
    timeoutSeconds: 30

  podLabels:
    backup.velero.io/custom-backup-daily-fs: "true"

  podAnnotations:
    backup.velero.io/backup-volumes: backup
    pre.hook.backup.velero.io/command: '["/bin/sh", "-c", "n8n export:credentials --all --decrypted | gzip > /scratch/n8n_credentials_backup.json.gz && n8n export:workflow --all --decrypted | gzip > /scratch/n8n_workflow_backup.json.gz"]'
    pre.hook.backup.velero.io/timeout: 60m
    post.hook.restore.velero.io/command: '["/bin/sh", "-c", "[ -f \"/scratch/n8n_credentials_backup.json.gz\" ] && gunzip /scratch/n8n_credentials_backup.json.gz && n8n import:credentials --input /scratch/n8n_credentials_backup.json && rm -f /scratch/n8n_credentials_backup.json; [ -f \"/scratch/n8n_workflow_backup.json.gz\" ] && gunzip /scratch/n8n_workflow_backup.json.gz && n8n import:workflow --input /scratch/n8n_workflow_backup.json && rm -f /scratch/n8n_workflow_backup.json;"]'

  extraVolumes: &extraVolumes
    - name: n8n-config-scripts
      configMap:
        name: "{{ .Values.release_name }}-automation-n8n-config-scripts"
    - name: n8n-secrets
      secret:
        secretName: n8n-secrets
    - name: backup
      emptyDir:
        sizeLimit: 100Mi

  extraVolumeMounts: &extraVolumeMounts
    - name: n8n-config-scripts
      mountPath: /n8n-config-scripts
      readOnly: true
    - name: n8n-secrets
      mountPath: /n8n-secrets
      readOnly: true
    - name: backup
      mountPath: /scratch

  resources:
    requests:
      memory: 256Mi
      cpu: 250m
    limits:
      memory: 1024Mi
      cpu: 1

worker:
  enabled: true

  replicaCount: 2
  concurrency: 4

  nodeSelector:
    kubernetes.io/arch: amd64

  tolerations:
    - effect: NoSchedule
      key: datahub.local/role
      operator: "Equal"
      value: nas

  command: *command
  podSecurityContext: *podSecurityContext

  readinessProbe: *readinessProbe
  livenessProbe:
    <<: *livenessProbe
    failureThreshold: 10

  extraEnv: *sharedEnv
  extraVolumes: *extraVolumes
  extraVolumeMounts: *extraVolumeMounts

  resources:
    requests:
      memory: 512Mi
      cpu: 500m
    limits:
      memory: 4098Mi
      cpu: 1

webhook:
  enabled: true

  command: *command
  podSecurityContext: *podSecurityContext

  readinessProbe: *readinessProbe
  livenessProbe: *livenessProbe

  extraEnv:
    <<: *sharedEnv

    NODE_OPTIONS:
      value: "--max-old-space-size=3072"
  extraVolumes: *extraVolumes
  extraVolumeMounts: *extraVolumeMounts

  resources:
    requests:
      memory: 128Mi
      cpu: 100m
    limits:
      memory: 512Mi
      cpu: 1

ingress:
  enabled: true
  annotations:
    #{{- if .Values.security_enabled }}{{ .Values.security_oauth2_annotations | toYaml | replace "SOME_REGEX_TO_SKIP" "(webhook|rest)/.*" | nindent 4 }}{{ end }}

    gethomepage.dev/enabled: "true"
    gethomepage.dev/name: "n8n"
    gethomepage.dev/pod-selector: "app.kubernetes.io/instance={{ .Values.release_name }}-automation-kopia"
    gethomepage.dev/description: "Fair-code workflow automation platform with native AI capabilities."
    gethomepage.dev/group: "Automation"
    gethomepage.dev/icon: "sh-n8n"

  className: nginx

  hosts:
    - host: *hostname
      paths:
        - /

  tls: {}

extraManifests:
  #{{- if .Values.security_enabled }}
  - apiVersion: v1
    kind: ConfigMap
    metadata:
      name: "{{ .Values.release_name }}-automation-n8n-config-scripts"
    data:
      n8n-ready-hook.js: |
        {{- readFile "../files/scripts/n8n/n8n-ready-hook.js" | nindent 8 }}
      n8n-start.sh: |
        {{- readFile "../files/scripts/n8n/n8n-start.sh" | nindent 8 }}
  #{{ end }}
  - apiVersion: monitoring.coreos.com/v1
    kind: PodMonitor
    metadata:
      name: "{{ .Values.release_name }}-automation-n8n"
    spec:
      podMetricsEndpoints:
        - path: /metrics
          port: http
      namespaceSelector:
        matchNames:
          - automation
      selector:
        matchLabels:
          app.kubernetes.io/instance: "{{ .Values.release_name }}-automation-n8n"
          app.kubernetes.io/name: n8n
          app.kubernetes.io/type: master
  - apiVersion: monitoring.coreos.com/v1
    kind: PodMonitor
    metadata:
      name: "{{ .Values.release_name }}-automation-n8n-worker"
    spec:
      podMetricsEndpoints:
        - path: /metrics
          port: http
      namespaceSelector:
        matchNames:
          - automation
      selector:
        matchLabels:
          app.kubernetes.io/instance: "{{ .Values.release_name }}-automation-n8n"
          app.kubernetes.io/name: n8n
          app.kubernetes.io/type: master
